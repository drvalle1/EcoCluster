---
title: "EcoCluster: Bayesian Clustering using Truncated Stick-Breaking priors "
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{EcoCluster}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

This vignette illustrates three different types of Bayesian clustering methods using truncated stick-breaking priors: mixture models, stochastic block models (SBM), and species archetype models (SAM). We apply these three clustering methods to simulated data to showcase how the number of groups can be successfully recovered.

# Mixture model

We start by generating simulated data:
```{r,eval=TRUE}
rm(list=ls(all=TRUE))
set.seed(1)

#general settings
nloc=300 #number of locations
nspp=50  #number of species
ngroup=5 #number of groups

#set parameters
z=sample(1:ngroup,size=nloc,replace=T)         #cluster assignment of each location
phi=matrix(rbeta(ngroup*nspp,1,1),ngroup,nspp) #species composition of each cluster  

#generate data
y=matrix(NA,nloc,nspp)
for (i in 1:nloc){
  phi1=phi[z[i],]
  y[i,]=rbinom(nspp,size=1,prob=phi1)
}
colnames(y)=paste0('spp',1:nspp)
rownames(y)=paste0('loc',1:nloc)

head(y[,1:13])
```

To obtain posterior samples from the mixture model parameters, we rely on the function `mixture.gibbs.main.func`. The user needs to specify the following arguments:

* `dat`:    binary matrix containing the data (rows are locations and columns are species) 
* `ngroup`: maximum number of groups
* `ngibbs`: number of iterations for the Gibbs sampler
* `burnin`: number of iterations to be discarded as burn-in.

```{r,eval=TRUE,results='hide'}
library('EcoCluster')
ngibbs=1000
res=mixture.gibbs.main.func(dat=y,ngroup=50,ngibbs=ngibbs,burnin=ngibbs/2)
```
```{r,eval=TRUE}
str(res)
```

The output is a list with 5 elements: 

* `phi`:   probability of observing each species in each group
* `theta`: probability of each location group
* `logl`:  log-likelihood 
* `z`:     cluster assignment of each location
* `gamma`: TSB prior parameter

The graph below with the log-likelihood suggests that this algorithm has successfully converged after discarding the burn-in iterations. 

```{r, eval=TRUE, fig.align='center'}
plot(res$logl,type='l',main='convergence assessment',xlab='Gibbs iterations',ylab='log-likelihood')
```

The next graph shows that the algorithm successfully identified the 5 true location groups, with the remaining groups being very small or empty.

```{r, eval=TRUE, fig.align='center'}
theta=colMeans(res$theta)
plot(theta[1:20],type='h',xlab='clusters',main='number of groups',ylab='theta',lwd=2)
abline(v=5,col='red',lty=3,lwd=0.1)
```

The estimated `phi` parameters can also be extracted and compared to the true `phi` parameter values. However, because the order of the groups might have changed (i.e., the first estimated group might not correspond to the first group in the simulated data), we have to re-order the groups to then compare the true and estimated `phi` values. This comparison reveals that our algorithm estimated well the `phi` parameters as most points fell near the 1:1 red line.

```{r, eval=TRUE, fig.align='center'}
#get posterior mean
phi.estim=matrix(colMeans(res$phi),nrow=50,ncol=nspp)
rownames(phi.estim)=paste0('groups',1:50)
colnames(phi.estim)=paste0('spp',1:nspp)

#eliminate superfluous groups
phi.estim1=phi.estim[1:5,]
round(phi.estim1[,1:10],2) #just show parameters for first 10 species

#re-order groups to make sure we are comparing the correct groups
table(data.frame(true.z=z,estim.z=res$z[nrow(res$z),]))
order1=c(5,1,3,2,4)
phi.estim2=phi.estim1[order1,]

#compare estimated to true phi parameters
plot(phi,phi.estim2,xlab='True values',ylab='Estimated values',
     xlim=c(0,1),ylim=c(0,1),main='phi parameters')
abline(coef=c(0,1),col='red',lwd=2)
```

# Stochastic block model

We start by generating simulated data:
```{r,eval=TRUE}
rm(list=ls(all=TRUE))
set.seed(1)

#general settings
nloc=300      #number of locations
nspp=50       #number of species
ngroup.loc=5  #number of location groups
ngroup.spp=3  #number of species groups

#set parameters
theta=rep(1/ngroup.loc,ngroup.loc)  #probability of each location group
phi=rep(1/ngroup.spp,ngroup.spp)    #probability of each species group

#probabilities associated with each location and species group
psi=matrix(c(0.05,0.5,0.95,
             0.5,0.05,0.95,
             0.05,0.95,0.5,
             0.5,0.95,0.05,
             0.1,0.5,0.05),ngroup.loc,ngroup.spp,byrow=T)

#get location group and species group assignments
z=sample(1:ngroup.loc,size=nloc,replace=T); 
w=sample(1:ngroup.spp,size=nspp,replace=T); 

#generate data
y=matrix(NA,nloc,nspp)
for (i in 1:nloc){
  for (j in 1:nspp){
    y[i,j]=rbinom(1,size=1,prob=psi[z[i],w[j]])    
  }
}
colnames(y)=paste0('spp',1:nspp)
rownames(y)=paste0('loc',1:nloc)
head(y[,1:13])
```

To obtain posterior samples from the stochastic block  model parameters, we rely on the function `SBM`. The user needs to specify the following arguments:

* `dat`:        binary matrix containing the data (rows are locations and columns are species) 
* `ngroup.loc`: maximum number of location groups
* `ngroup.spp`: maximum number of species groups
* `ngibbs`:     number of iterations for the Gibbs sampler
* `burnin`:     number of iterations to be discarded as burn-in.

```{r,eval=TRUE,results='hide'}
library('EcoCluster')
ngibbs=1000
res=SBM(dat=y,ngroup.loc=50,ngroup.spp=50,ngibbs=ngibbs,burnin=ngibbs/2)
```
```{r,eval=TRUE}
str(res)
```

The output is a list with 7 elements: 

* `theta`: probability of each location group
* `phi`:   probability of each species group
* `llk`:   log-likelihood
* `psi`:   presence probability for each location group and species group
* `z`:     cluster assignment of each location
* `w`:     cluster assignment of each species
* `gamma`: TSB prior parameters (one for location groups and the other for species groups)

The graph below with the log-likelihood suggests that this algorithm has successfully converged after discarding the burn-in iterations. 

```{r,eval=TRUE, fig.align='center'}
plot(res$llk,type='l',main='convergence assessment',xlab='Gibbs iterations',ylab='log-likelihood')
```

The next two graphs show that the algorithm successfully identified the 5 true location groups and 3 true species groups.

```{r,eval=TRUE, fig.align='center'}
theta=colMeans(res$theta)
plot(theta[1:20],type='h',xlab='clusters',main='number of location groups',ylab='theta',lwd=2)
abline(v=5,col='red',lty=3,lwd=0.1)

phi=colMeans(res$phi)
plot(phi[1:20],type='h',xlab='clusters',main='number of species groups',ylab='phi',lwd=2)
abline(v=3,col='red',lty=3,lwd=0.1)
```

The estimated `psi` parameters can also be extracted and compared to the true `psi` parameter values. However, because the order of the groups might have changed (i.e., the first estimated group might not correspond to the first group in the simulated data), we have to re-order the groups to then compare the true and estimated `psi` values. This comparison reveals that our algorithm estimated well the `psi` parameters as most points fell near the 1:1 red line.

```{r, eval=TRUE, fig.align='center'}
#get posterior mean
psi.estim=matrix(colMeans(res$psi),nrow=50,ncol=50)
rownames(psi.estim)=paste0('location.groups',1:50)
colnames(psi.estim)=paste0('spp.groups',1:50)

#eliminate superfluous groups
psi.estim1=psi.estim[1:5,]
psi.estim2=psi.estim1[,1:3]
round(psi.estim2,2) #show estimated parameters

#re-order groups to make sure we are comparing the correct groups
table(data.frame(true.z=z,estim.z=res$z[nrow(res$z),]))
ord.location.grps=c(4,3,1,2,5)
psi.estim3=psi.estim2[ord.location.grps,]

table(data.frame(true.w=w,estim.w=res$w[nrow(res$w),]))
ord.spp.grps=c(1,3,2)
psi.estim4=psi.estim3[,ord.spp.grps]

#compare estimated to true parameter values
plot(psi,psi.estim4,xlab='True values',ylab='Estimated values',
     xlim=c(0,1),ylim=c(0,1),main='psi parameters')
abline(coef=c(0,1),col='red',lwd=2)
```

# Species Archetype model

We start by generating simulated data:
```{r,eval=TRUE}
rm(list=ls(all=TRUE))
library('mvtnorm')
set.seed(1)

#general settings
nloc=300   #number of locations
nspp=50    #number of species
nparam=6   #number of covariates
ngroup1=5  #number of species groups

#create design matrix with covariates
xmat=matrix(rnorm(nparam*nloc),nloc,nparam)

#set parameters
alpha=rnorm(nspp,mean=0,sd=0.4) #intercept of each species
tmp=rnorm(nparam*ngroup1)
betas=matrix(tmp,nparam,ngroup1) #slope parameters for each group
cs=sample(1:ngroup1,size=nspp,replace=T) #cluster assignment for each species

#generate data assuming a probit formulation    
omega=matrix(NA,nloc,nspp)
for (i in 1:nspp){
  media=alpha[i]+xmat%*%betas[,cs[i]]
  omega[,i]=rnorm(nloc,mean=media,sd=1)
}
y=omega.true=omega
y[omega>0]=1
y[omega<0]=0

colnames(y)=paste0('spp',1:nspp)
rownames(y)=paste0('loc',1:nloc)
head(y[,1:13])
```

To obtain posterior samples from the species archetype model parameters, we rely on the function `gibbs.SAM`. The user needs to specify the following arguments:

* `y`:       binary matrix containing the data (rows are locations and columns are species)
* `xmat`:    matrix containing the predictor variables (rows are locations and columns are predictor variables)
* `ngroups`: maximum number of species groups
* `ngibbs`:  number of iterations for the Gibbs sampler
* `burnin`:  number of iterations to be discarded as burn-in.

```{r, eval=TRUE, results='hide'}
library('EcoCluster')
ngibbs=1000

res=gibbs.SAM(y=y,xmat=xmat,ngroups=50,ngibbs=ngibbs,burnin=ngibbs/2)
```
```{r,eval=TRUE}
str(res)
```

The output is a list with 6 elements: 

* `theta`: probability of each species group
* `logl`:  log-likelihood
* `betas`: slope parameters for each group
* `cs`:    cluster assignment of each species
* `alpha`: intercept of each species
* `gamma`: TSB prior parameter

The graph below with the log-likelihood suggests that this algorithm has successfully converged after discarding the burn-in iterations. 

```{r, eval=TRUE, fig.align='center'}
plot(res$logl,type='l',main='convergence assessment',xlab='Gibbs iterations',ylab='log-likelihood')
```

The next graph shows that the algorithm successfully identified the 5 true species groups.

```{r, eval=TRUE, fig.align='center'}
theta=colMeans(res$theta)
plot(theta[1:20],type='h',xlab='clusters',main='number of species groups',ylab='theta',lwd=2)
abline(v=5,col='red',lty=3,lwd=0.1)
```

The estimated `alpha` parameters can also be extracted and compared to the true `alpha` parameter values. This comparison reveals that our algorithm estimated well the `alpha` parameters as most points fell near the 1:1 red line.

```{r, eval=TRUE, fig.align='center'}
#get posterior mean of species specific intercepts
alpha.estim=colMeans(res$alpha)

#compare estimated to true parameter values
range1=range(c(alpha,alpha.estim))
plot(alpha,alpha.estim,xlab='True values',ylab='Estimated values',
     xlim=range1,ylim=range1,main='alpha parameters')
abline(coef=c(0,1),col='red',lwd=2)
```

The estimated `betas` parameters can also be extracted and compared to the true `betas` parameter values. However, because the order of the groups might have changed (i.e., the first estimated group might not correspond to the first group in the simulated data), we have to re-order the groups to then compare the true and estimated parameters. This comparison reveals that our algorithm estimated well the `betas` parameters as most points fell near the 1:1 red line.

```{r, eval=TRUE, fig.align='center'}
#get posterior mean
betas.estim=matrix(colMeans(res$betas),nrow=nparam,ncol=50)
rownames(betas.estim)=paste0('covariate',1:nparam)
colnames(betas.estim)=paste0('spp.groups',1:50)

#eliminate superfluous groups
betas.estim1=betas.estim[,1:5]
round(betas.estim1,2) #look at estimated regression coefficients

#re-order groups to make sure we are comparing the correct groups
table(data.frame(true.cs=cs,estim.cs=res$cs[nrow(res$cs),]))
ord.spp.grps=c(2,4,5,3,1)
betas.estim2=betas.estim1[,ord.spp.grps]

#compare estimated to true parameters values
range1=range(c(betas,betas.estim2))
plot(betas,betas.estim2,xlab='True values',ylab='Estimated values',
     xlim=range1,ylim=range1,main='beta parameters')
abline(coef=c(0,1),col='red',lwd=2)
```